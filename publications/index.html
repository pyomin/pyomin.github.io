<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Pyo Min Hong </title> <meta name="author" content="Pyo Min Hong"> <meta name="description" content="Publications are listed in reverse chronological order. &lt;br/&gt; (*) denotes equal contribution"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/animated.gif?68b851042db05aa2222face22c0729dd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pyomin.github.io/publications/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Pyo Min Hong </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">Publications are listed in reverse chronological order. <br> (*) denotes equal contribution</p> </header> <article> <div class="publications"> <h2 class="bibliography">2026</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/dgmark_mb-480.webp 480w,/assets/img/publication_preview/dgmark_mb-800.webp 800w,/assets/img/publication_preview/dgmark_mb-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/dgmark_mb.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dgmark_mb.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="hong2026dgmark" class="col-sm-8"> <div class="title">dgMARK: Decoding-Guided Watermarking for Diffusion Language Models</div> <div class="author"> <em>Pyo Min Hong</em> ,  and  Albert No </div> <div class="periodical"> <em>arXiv preprint</em>, 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2601.22985" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://dgMARK-watermarking.github.io" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>We propose dgMARK, a decoding-guided watermarking method for discrete diffusion language models (dLLMs). Unlike autoregressive models, dLLMs can generate tokens in arbitrary order. While an ideal conditional predictor would be invariant to this order, practical dLLMs exhibit strong sensitivity to the unmasking order, creating a new channel for watermarking. dgMARK steers the unmasking order toward positions whose high-reward candidate tokens satisfy a simple parity constraint induced by a binary hash, without explicitly reweighting the model’s learned probabilities. The method is plug-and-play with common decoding strategies (e.g., confidence, entropy, and margin-based ordering) and can be strengthened with a one-step lookahead variant. Watermarks are detected via elevated parity-matching statistics, and a sliding-window detector ensures robustness under post-editing operations including insertion, deletion, substitution, and paraphrasing.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/UDD-480.webp 480w,/assets/img/publication_preview/UDD-800.webp 800w,/assets/img/publication_preview/UDD-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/UDD.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="UDD.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="hong20252" class="col-sm-8"> <div class="title">Zero-shot Inverse Imaging with Auto-tuned Hyperparameters and Untrained Generative Priors</div> <div class="author"> <em>Pyo Min Hong</em> ,  Jung Won Yoon ,  Hyun Jun Yook ,  Youn Kyu Lee ,  and  Tae Hyung Kim </div> <div class="periodical"> <em>Under Review</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/UDD-480.webp 480w,/assets/img/publication_preview/UDD-800.webp 800w,/assets/img/publication_preview/UDD-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/UDD.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="UDD.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="hong2025" class="col-sm-8"> <div class="title">No Clean Example Required: Resilient and Robust Defense Against Adversarial Attacks</div> <div class="author"> <em>Pyo Min Hong</em> ,  Hyun Jun Yook ,  Jung Won Yoon ,  So Hyun Kang ,  Tae Hyung Kim ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>Under Review</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/waveform-480.webp 480w,/assets/img/publication_preview/waveform-800.webp 800w,/assets/img/publication_preview/waveform-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/waveform.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="waveform.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Imgwaveform" class="col-sm-8"> <div class="title">A New Wave of Texture Feature: Enhancing Deepfake Detection via Image Waveform</div> <div class="author"> Ga San Jhun ,  <em>Pyo Min Hong</em> ,  Keun Lee ,  Jong Hyun Ahn ,  Young Seon Kim ,  Dongwoo Kang , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Youn Kyu Lee' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In 2024 15th International Conference on Information and Communication Technology Convergence (ICTC)</em> , 2024 </div> <div class="periodical"> </div> <div class="honor" style="color: #007bff;">Best paper award</div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/abstract/document/10827484" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>To address the security threats posed by highly realistic deepfakes, various deepfake detection methods have been proposed. In particular, texture features resulting from the post-processing steps in deepfake generation, such as color correction and edge smoothing have been widely utilized in deepfake detection methods. However their detection method is limited against advanced image synthesis mechanisms. In this paper, we propose a novel deepfake detection method based on texture features, an Image Waveform. Our proposed method converts the pixel values of an image into an Image Waveform to enhance texture features and utilizes two-stream CNN to maximize deepfake detection performance by effectively leveraging the features of the original image. Experimental results of real-world deepfake dataset, confirmed that our proposed method achieves higher detection accuracy compared to existing texture feature-based detection methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/attention-480.webp 480w,/assets/img/publication_preview/attention-800.webp 800w,/assets/img/publication_preview/attention-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/attention.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="attention.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="AttentionMap" class="col-sm-8"> <div class="title">Attention Map Is All We Need for Lightweight Fingerprint Liveness Detection</div> <div class="author"> Hyun Jun Yook ,  <em>Pyo Min Hong</em> ,  So Hyun Kang ,  Ga San Jhun ,  Jae Eun Seo ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>IEEE Access</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/document/10677437" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>To counter the security threats posed by presentation attacks on fingerprint authentication systems, various deep learning-based fingerprint liveness detection methods have been proposed. However, existing methods typically require significant computing resources or lengthy detection times to achieve high accuracy, which can limit their use in resource-constrained environments such as on-device applications. In this paper, we propose a novel fingerprint liveness detection method that utilizes a Multi-head Self-Attention mechanism. By focusing on important regions of fingerprint images, our proposed method maximizes detection accuracy while simultaneously minimizing both model size and detection time. Our evaluation on real-world datasets demonstrates that our proposed method achieves detection accuracy comparable to state-of-the-art methods while requiring the smallest model size and the least detection time, confirming that our proposed method is the most efficient liveness detection method available.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/orthogonal-480.webp 480w,/assets/img/publication_preview/orthogonal-800.webp 800w,/assets/img/publication_preview/orthogonal-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/orthogonal.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="orthogonal.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Orthogonal" class="col-sm-8"> <div class="title">Orthogonal Transform-Driven Data Augmentation for Limited Gaussian-Tainted Dataset</div> <div class="author"> Jung Won Yoon ,  Hyun Jun Yook ,  <em>Pyo Min Hong</em> ,  Youn Kyu Lee ,  and  Tae Hyung Kim </div> <div class="periodical"> <em>IEEE Access</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/document/10668869" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>A large amount of data collected from sensors exhibits Gaussian noise characteristics, making denoising and related processing critical. However, data scarcity can lead to overfitting, posing challenges in training deep learning-based denoising methods. While various data augmentation methods have been proposed, they do not provide a means to augment original data to large-scale data while preserving the exact noise distribution. To address this, we introduce a novel data augmentation method for data with additive white Gaussian noise (AWGN). Our method is based on two main premises: first, orthogonal transforms preserve the probability distribution of AWGN; second, the signals we aim to recover generally exhibit smooth characteristics, unlike noise. Building on these premises, we propose adaptive smoothnesspromoting orthogonal transforms for augmenting limited existing data. We evaluated the proposed method in Gaussian denoising tasks with limited data and confirmed that it achieves substantial improvement in deep learning model performance, comparable to those obtained with sufficient data.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/analysis3-480.webp 480w,/assets/img/publication_preview/analysis3-800.webp 800w,/assets/img/publication_preview/analysis3-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/analysis3.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="analysis3.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="RiskAnalysis" class="col-sm-8"> <div class="title">A Comprehensive Risk Analysis Method for Adversarial Attacks on Biometric Authentication Systems</div> <div class="author"> Seong Hee Park ,  Soo-Hyun Lee ,  Min Young Lim ,  <em>Pyo Min Hong</em> ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>IEEE Access</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/document/10630524" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>Recent threats to deep learning-based biometric authentication systems stem from adversarial attacks exploiting vulnerabilities in deep learning models. While existing studies extensively analyze the risk of such attacks, they primarily focus on isolated modules (e.g., liveness detectors or identity matchers) or specific adversarial attack types (e.g., evasion and poisoning attacks). In this paper, we introduce a novel approach that comprehensively assesses the risk of adversarial attacks by simulating multiple scenarios within biometric authentication systems. We identify the surfaces susceptible to adversarial attacks within these systems and devise scenarios that reflect the dependencies between modules. Moreover, we establish evaluation metrics to comprehensively assess the risk involved. Through a case study conducted on a real-world face recognition system, we successfully demonstrate the effectiveness of our approach. Our approach facilitates the systematic evaluation of the security of target biometric authentication systems against adversarial attacks. Ultimately, it enables the establishment of robust and proactive defense mechanisms.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/velcro-480.webp 480w,/assets/img/publication_preview/velcro-800.webp 800w,/assets/img/publication_preview/velcro-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/velcro.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="velcro.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Velcro" class="col-sm-8"> <div class="title">VELCRO: A visual-based programming tool for effortless deep learning model construction</div> <div class="author"> Min Young Lim* ,  Seong Hee Park* ,  Soo-Hyun Lee* ,  Jung Won Yoon* ,  <em>Pyo Min Hong*</em> ,  Hwajung Yoo* , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Kon-Woo Kwon, Jongwook Jeong, Youn Kyu Lee' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>SoftwareX</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://www.sciencedirect.com/science/article/pii/S235271102400027X" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>The development and deployment of deep learning models are currently limited to expert developers due to the requirement for programming expertise, posing challenges for non-expert or inexperienced developers. In this paper, we present VELCRO, a visual-based programming tool that enables intuitive construction, modification, analysis, and generation of deep learning models for both expert and non-expert developers. VELCRO allows users to understand and modify complex architectures of deep learning models using architecture abstraction, and verify architectures through automated architecture validation. Finally, users can convert the user-configured architecture into deep learning code and deploy it in target environments.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/adv2adv-480.webp 480w,/assets/img/publication_preview/adv2adv-800.webp 800w,/assets/img/publication_preview/adv2adv-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/adv2adv.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="adv2adv.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Adv2Adv" class="col-sm-8"> <div class="title">Adversarial2Adversarial: Defending against Adversarial Fingerprint Attacks without Clean Images</div> <div class="author"> <em>Pyo Min Hong</em> ,  So Hyun Kang ,  Jinhyeon Kim ,  Ji Hoo Kim ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>In 2023 14th International Conference on Information and Communication Technology Convergence (ICTC)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://ieeexplore.ieee.org/abstract/document/10392544" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>A number of denoising-based methods have been proposed to defend against adversarial fingerprint attacks. However, these methods inherently rely on having a clean image that corresponds to each adversarial fingerprint image. In this paper, we propose a novel denoising-based defense method without the need for clean fingerprint images. Our approach leverages a Noise2Noise mechanism, which performs denoising based on the noisy dataset. This enables us to effectively eliminate any adversarial noise that may be embedded in fingerprint images without training on clean fingerprint images. The experimental results on real-world datasets confirm that our method is robust against untrained adversarial fingerprint attacks while outperforming existing methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2stage-480.webp 480w,/assets/img/publication_preview/2stage-800.webp 800w,/assets/img/publication_preview/2stage-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/2stage.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2stage.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Purification" class="col-sm-8"> <div class="title">Two-Stage Image Restoration: A Shield against Adversarial Attacks on Face Identification</div> <div class="author"> Min Young Lim ,  <em>Pyo Min Hong</em> ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>In 2023 14th International Conference on Information and Communication Technology Convergence (ICTC)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://ieeexplore.ieee.org/abstract/document/10393701" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>Various methods have been proposed to defend face identification systems against adversarial attacks by eliminating adversarial perturbations from target face images. However, it is challenging to eliminate such perturbations while preserving the crucial facial features within the images. In this paper, we propose a novel purification method for an effective defense against adversarial attacks on target face images. Our method incorporates a two-stage image restoration utilizing diffusion, consisting of sequential super-resolution-based image restoration followed by colorization-based image restoration. The experimental results demonstrate the effectiveness of our method in eliminating perturbations while preserving the identity of the facial features.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DIP_preview-480.webp 480w,/assets/img/publication_preview/DIP_preview-800.webp 800w,/assets/img/publication_preview/DIP_preview-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/DIP_preview.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DIP_preview.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DipRecon" class="col-sm-8"> <div class="title">Defending Against Adversarial Fingerprint Attacks Based on Deep Image Prior</div> <div class="author"> Hwajung Yoo ,  <em>Pyo Min Hong</em> ,  Taeyong Kim ,  Jung Won Yoon ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>IEEE Access</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://ieeexplore.ieee.org/abstract/document/10196440" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>Recently, deep learning-based biometric authentication systems, especially fingerprint authentication, have been used widely in real-world. However, these systems are vulnerable to adversarial attacks which prevent deep learning models from distinguishing input data properly. To solve these problems, various defense methods have been proposed, especially utilizing denoising mechanisms, but they provided limited defense performance. In this study, we proposed a new defense method against adversarial fingerprint attacks. To ensure defense performance, we have introduced Deep Image Prior mechanism which has superior performance in image reconstruction without prior training and a large amount of dataset. The proposed method aims to remove adversarial perturbations of the input fingerprint image and reconstruct it close to the original fingerprint image by adapting Deep Image Prior. Our method has achieved robust defense performance against various types of adversarial fingerprint attacks across different datasets, encompassing variations in sensors, shapes, and materials of fingerprint images. Furthermore, our method has demonstrated that it is superior to other image reconstruction methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/KICS-480.webp 480w,/assets/img/publication_preview/KICS-800.webp 800w,/assets/img/publication_preview/KICS-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/KICS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="KICS.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="KICS" class="col-sm-8"> <div class="title">A Study on Adversarial Fingerprint Defense Using Self-Supervised Denoising from Single Image</div> <div class="author"> <em>Pyo Min Hong</em> ,  Hwajung Yoo ,  Taeyong Kim ,  Jung Won Yoon ,  Tae Hyung Kim ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>The Journal of Korean Institute of Communications and Information Sciences</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://engjournal.kics.or.kr/digital-library/50812" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>Adversarial fingerprint attacks exploit deep learning-based fingerprint authentication systems, causing abnormal behavior in the model. The emergence of various forms of adversarial attacks has created vulnerabilities in deep learning-based fingerprint authentication systems, leading to a new security issue. In this paper, we propose a defense mechanism that provides generalized performance against various adversarial fingerprint attacks without requiring multiple types of fingerprint images. The proposed method utilizes a single image-based self-supervised denoising technique to effectively remove adversarial noise from input fingerprint images while restoring them to their original state, providing robust defense performance against adversarial fingerprint attacks. Furthermore, it offers superior defense performance compared to existing image restoration methods without requiring pre-training on large-scale fingerprint images.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/central-480.webp 480w,/assets/img/publication_preview/central-800.webp 800w,/assets/img/publication_preview/central-1400.webp 1400w," sizes="350px" type="image/webp"></source> <img src="/assets/img/publication_preview/central.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="central.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="CentralPoint" class="col-sm-8"> <div class="title">A Central Point-based Analysis for Fingerprint Liveness Detection</div> <div class="author"> Min Young Lim* ,  Tae Yong Kim* ,  Joung Eun Park* ,  <em>Pyo Min Hong*</em> ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>In 2022 13th International Conference on Information and Communication Technology Convergence (ICTC)</em> , 2022 </div> <div class="periodical"> </div> <div class="honor" style="color: #007bff;">Best paper award</div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://ieeexplore.ieee.org/abstract/document/9952772" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>To minimize security threats using fake fingerprints, various CNN-based fingerprint liveness detection methods have been proposed. However, since existing methods mainly employ a random crop method, key information of target fingerprint may be overlooked during the training process, which may lead to decreased detection accuracy. In this paper, we propose a new fingerprint liveness detection method based on central point analysis of fingerprints. The proposed method measures a central point of target fingerprint, extracts the crops with different sizes based on the central point, and fuses the liveness scores inferred from each crop-size model. As a result of validating our method using real datasets, it was confirmed that our method effectively detects fake fingerprints compared to existing methods.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Pyo Min Hong. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Last updated: February 14, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>