<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Pyo Min Hong </title> <meta name="author" content="Pyo Min Hong"> <meta name="description" content="Publications are listed in reverse chronological order. &lt;br/&gt; (*) denotes equal contribution"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/animated.gif?68b851042db05aa2222face22c0729dd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pyomin.github.io/publications/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Pyo Min Hong </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">Publications are listed in reverse chronological order. <br> (*) denotes equal contribution</p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/attention-480.webp 480w,/assets/img/publication_preview/attention-800.webp 800w,/assets/img/publication_preview/attention-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/attention.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="attention.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="AttentionMap" class="col-sm-8"> <div class="title">Attention Map Is All We Need for Lightweight Fingerprint Liveness Detection</div> <div class="author"> Hyun Jun Yook ,  <em>Pyo Min Hong</em> ,  So Hyun Kang ,  Ga San Jhun ,  Jae Eun Seo ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>IEEE Access</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10677437" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>To counter the security threats posed by presentation attacks on fingerprint authentication systems, various deep learning-based fingerprint liveness detection methods have been proposed. However, existing methods typically require significant computing resources or lengthy detection times to achieve high accuracy, which can limit their use in resource-constrained environments such as on-device applications. In this paper, we propose a novel fingerprint liveness detection method that utilizes a Multi-head Self-Attention mechanism. By focusing on important regions of fingerprint images, our proposed method maximizes detection accuracy while simultaneously minimizing both model size and detection time. Our evaluation on real-world datasets demonstrates that our proposed method achieves detection accuracy comparable to state-of-the-art methods while requiring the smallest model size and the least detection time, confirming that our proposed method is the most efficient liveness detection method available.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">AttentionMap</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yook, Hyun Jun and Hong, Pyo Min and Kang, So Hyun and Jhun, Ga San and Seo, Jae Eun and Lee, Youn Kyu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Attention Map Is All We Need for Lightweight Fingerprint Liveness Detection}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-1}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Fingerprint recognition;Feature extraction;Image matching;Accuracy;Training;Convolutional neural networks;Authentication;Fingerprint liveness detection;lightweight method;multi-head self-attention;fingerprint authentication;presentation attacks}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2024.3458908}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/orthogonal-480.webp 480w,/assets/img/publication_preview/orthogonal-800.webp 800w,/assets/img/publication_preview/orthogonal-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/orthogonal.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="orthogonal.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Orthogonal" class="col-sm-8"> <div class="title">Orthogonal Transform-Driven Data Augmentation for Limited Gaussian-Tainted Dataset</div> <div class="author"> Jung Won Yoon ,  Hyun Jun Yook ,  <em>Pyo Min Hong</em> ,  Youn Kyu Lee ,  and  Tae Hyung Kim </div> <div class="periodical"> <em>IEEE Access</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10668869" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>A large amount of data collected from sensors exhibits Gaussian noise characteristics, making denoising and related processing critical. However, data scarcity can lead to overfitting, posing challenges in training deep learning-based denoising methods. While various data augmentation methods have been proposed, they do not provide a means to augment original data to large-scale data while preserving the exact noise distribution. To address this, we introduce a novel data augmentation method for data with additive white Gaussian noise (AWGN). Our method is based on two main premises: first, orthogonal transforms preserve the probability distribution of AWGN; second, the signals we aim to recover generally exhibit smooth characteristics, unlike noise. Building on these premises, we propose adaptive smoothnesspromoting orthogonal transforms for augmenting limited existing data. We evaluated the proposed method in Gaussian denoising tasks with limited data and confirmed that it achieves substantial improvement in deep learning model performance, comparable to those obtained with sufficient data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Orthogonal</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yoon, Jung Won and Yook, Hyun Jun and Hong, Pyo Min and Lee, Youn Kyu and Kim, Tae Hyung}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Orthogonal Transform-Driven Data Augmentation for Limited Gaussian-Tainted Dataset}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-1}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Transforms;Noise reduction;Data augmentation;Training data;Noise measurement;Gaussian noise;Data collection;Data Augmentation;Smoothness-promoting Orthogonal Transform;Gaussian Noise}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2024.3455376}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/analysis3-480.webp 480w,/assets/img/publication_preview/analysis3-800.webp 800w,/assets/img/publication_preview/analysis3-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/analysis3.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="analysis3.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="RiskAnalysis" class="col-sm-8"> <div class="title">A Comprehensive Risk Analysis Method for Adversarial Attacks on Biometric Authentication Systems</div> <div class="author"> Seong Hee Park ,  Soo-Hyun Lee ,  Min Young Lim ,  <em>Pyo Min Hong</em> ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>IEEE Access</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10630524" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Recent threats to deep learning-based biometric authentication systems stem from adversarial attacks exploiting vulnerabilities in deep learning models. While existing studies extensively analyze the risk of such attacks, they primarily focus on isolated modules (e.g., liveness detectors or identity matchers) or specific adversarial attack types (e.g., evasion and poisoning attacks). In this paper, we introduce a novel approach that comprehensively assesses the risk of adversarial attacks by simulating multiple scenarios within biometric authentication systems. We identify the surfaces susceptible to adversarial attacks within these systems and devise scenarios that reflect the dependencies between modules. Moreover, we establish evaluation metrics to comprehensively assess the risk involved. Through a case study conducted on a real-world face recognition system, we successfully demonstrate the effectiveness of our approach. Our approach facilitates the systematic evaluation of the security of target biometric authentication systems against adversarial attacks. Ultimately, it enables the establishment of robust and proactive defense mechanisms.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">RiskAnalysis</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Park, Seong Hee and Lee, Soo-Hyun and Lim, Min Young and Hong, Pyo Min and Lee, Youn Kyu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Comprehensive Risk Analysis Method for Adversarial Attacks on Biometric Authentication Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{116693-116710}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Biometrics (access control);Authentication;Biological system modeling;Detectors;Training;Databases;Deep learning;Adversarial machine learning;Risk management;Adversarial attack;adversarial attack scenarios;biometric authentication system;comprehensive risk analysis;deep learning}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2024.3439741}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/velcro-480.webp 480w,/assets/img/publication_preview/velcro-800.webp 800w,/assets/img/publication_preview/velcro-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/velcro.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="velcro.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Velcro" class="col-sm-8"> <div class="title">VELCRO: A visual-based programming tool for effortless deep learning model construction</div> <div class="author"> Min Young Lim* ,  Seong Hee Park* ,  Soo-Hyun Lee* ,  Jung Won Yoon* ,  <em>Pyo Min Hong*</em> ,  Hwajung Yoo* , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Kon-Woo Kwon, Jongwook Jeong, Youn Kyu Lee' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>SoftwareX</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://www.sciencedirect.com/science/article/pii/S235271102400027X" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>The development and deployment of deep learning models are currently limited to expert developers due to the requirement for programming expertise, posing challenges for non-expert or inexperienced developers. In this paper, we present VELCRO, a visual-based programming tool that enables intuitive construction, modification, analysis, and generation of deep learning models for both expert and non-expert developers. VELCRO allows users to understand and modify complex architectures of deep learning models using architecture abstraction, and verify architectures through automated architecture validation. Finally, users can convert the user-configured architecture into deep learning code and deploy it in target environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Velcro</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{VELCRO: A visual-based programming tool for effortless deep learning model construction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lim*, Min Young and Park*, Seong Hee and Lee*, Soo-Hyun and Yoon*, Jung Won and Hong*, Pyo Min and Yoo*, Hwajung and Kwon, Kon-Woo and Jeong, Jongwook and Lee, Youn Kyu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{SoftwareX}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{26}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{101656}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/adv2adv-480.webp 480w,/assets/img/publication_preview/adv2adv-800.webp 800w,/assets/img/publication_preview/adv2adv-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/adv2adv.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="adv2adv.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Adv2Adv" class="col-sm-8"> <div class="title">Adversarial2Adversarial: Defending against Adversarial Fingerprint Attacks without Clean Images</div> <div class="author"> <em>Pyo Min Hong</em> ,  So Hyun Kang ,  Jinhyeon Kim ,  Ji Hoo Kim ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>In 2023 14th International Conference on Information and Communication Technology Convergence (ICTC)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/abstract/document/10392544" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>A number of denoising-based methods have been proposed to defend against adversarial fingerprint attacks. However, these methods inherently rely on having a clean image that corresponds to each adversarial fingerprint image. In this paper, we propose a novel denoising-based defense method without the need for clean fingerprint images. Our approach leverages a Noise2Noise mechanism, which performs denoising based on the noisy dataset. This enables us to effectively eliminate any adversarial noise that may be embedded in fingerprint images without training on clean fingerprint images. The experimental results on real-world datasets confirm that our method is robust against untrained adversarial fingerprint attacks while outperforming existing methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Adv2Adv</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adversarial2Adversarial: Defending against Adversarial Fingerprint Attacks without Clean Images}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hong, Pyo Min and Hyun Kang, So and Kim, Jinhyeon and Kim, Ji Hoo and Kyu Lee, Youn}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 14th International Conference on Information and Communication Technology Convergence (ICTC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1278-1282}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Training;Image matching;Face recognition;Noise reduction;Fingerprint recognition;Information and communication technology;Noise measurement;fingerprint liveness detection;adversarial attack;deep learning;denoising}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICTC58733.2023.10392544}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2stage-480.webp 480w,/assets/img/publication_preview/2stage-800.webp 800w,/assets/img/publication_preview/2stage-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/2stage.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2stage.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Purification" class="col-sm-8"> <div class="title">Two-Stage Image Restoration: A Shield against Adversarial Attacks on Face Identification</div> <div class="author"> Min Young Lim ,  <em>Pyo Min Hong</em> ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>In 2023 14th International Conference on Information and Communication Technology Convergence (ICTC)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/abstract/document/10393701" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Various methods have been proposed to defend face identification systems against adversarial attacks by eliminating adversarial perturbations from target face images. However, it is challenging to eliminate such perturbations while preserving the crucial facial features within the images. In this paper, we propose a novel purification method for an effective defense against adversarial attacks on target face images. Our method incorporates a two-stage image restoration utilizing diffusion, consisting of sequential super-resolution-based image restoration followed by colorization-based image restoration. The experimental results demonstrate the effectiveness of our method in eliminating perturbations while preserving the identity of the facial features.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Purification</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lim, Min Young and Hong, Pyo Min and Lee, Youn Kyu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 14th International Conference on Information and Communication Technology Convergence (ICTC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Two-Stage Image Restoration: A Shield against Adversarial Attacks on Face Identification}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1283-1285}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Purification;Perturbation methods;Superresolution;Distortion;Image restoration;Information and communication technology;Faces;defense against adversarial attacks;deep learning;face identification;image restoration}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICTC58733.2023.10393701}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DIP_preview-480.webp 480w,/assets/img/publication_preview/DIP_preview-800.webp 800w,/assets/img/publication_preview/DIP_preview-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/DIP_preview.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DIP_preview.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="DipRecon" class="col-sm-8"> <div class="title">Defending Against Adversarial Fingerprint Attacks Based on Deep Image Prior</div> <div class="author"> Hwajung Yoo ,  <em>Pyo Min Hong</em> ,  Taeyong Kim ,  Jung Won Yoon ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>IEEE Access</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/abstract/document/10196440" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Recently, deep learning-based biometric authentication systems, especially fingerprint authentication, have been used widely in real-world. However, these systems are vulnerable to adversarial attacks which prevent deep learning models from distinguishing input data properly. To solve these problems, various defense methods have been proposed, especially utilizing denoising mechanisms, but they provided limited defense performance. In this study, we proposed a new defense method against adversarial fingerprint attacks. To ensure defense performance, we have introduced Deep Image Prior mechanism which has superior performance in image reconstruction without prior training and a large amount of dataset. The proposed method aims to remove adversarial perturbations of the input fingerprint image and reconstruct it close to the original fingerprint image by adapting Deep Image Prior. Our method has achieved robust defense performance against various types of adversarial fingerprint attacks across different datasets, encompassing variations in sensors, shapes, and materials of fingerprint images. Furthermore, our method has demonstrated that it is superior to other image reconstruction methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DipRecon</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yoo, Hwajung and Hong, Pyo Min and Kim, Taeyong and Yoon, Jung Won and Lee, Youn Kyu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Defending Against Adversarial Fingerprint Attacks Based on Deep Image Prior}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{78713-78725}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Fingerprint recognition;Image reconstruction;Image matching;Perturbation methods;Electronics packaging;Noise reduction;Generative adversarial networks;Deep learning;Biometrics (access control);Computer security;Authentication;Adversarial attack defense;image reconstruction;fingerprint authentication system;deep learning;denoising;deep image prior}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2023.3299862}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/KICS-480.webp 480w,/assets/img/publication_preview/KICS-800.webp 800w,/assets/img/publication_preview/KICS-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/KICS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="KICS.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="KICS" class="col-sm-8"> <div class="title">A Study on Adversarial Fingerprint Defense Using Self-Supervised Denoising from Single Image</div> <div class="author"> <em>Pyo Min Hong</em> ,  Hwajung Yoo ,  Taeyong Kim ,  Jung Won Yoon ,  Tae Hyung Kim ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>The Journal of Korean Institute of Communications and Information Sciences</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://engjournal.kics.or.kr/digital-library/50812" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>The development and deployment of deep learning models are currently limited to expert developers due to the requirement for programming expertise, posing challenges for non-expert or inexperienced developers. In this paper, we present VELCRO, a visual-based programming tool that enables intuitive construction, modification, analysis, and generation of deep learning models for both expert and non-expert developers. VELCRO allows users to understand and modify complex architectures of deep learning models using architecture abstraction, and verify architectures through automated architecture validation. Finally, users can convert the user-configured architecture into deep learning code and deploy it in target environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">KICS</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Study on Adversarial Fingerprint Defense Using Self-Supervised Denoising from Single Image}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hong, Pyo Min and Yoo, Hwajung and Kim, Taeyong and Yoon, Jung Won and Kim, Tae Hyung and Lee, Youn Kyu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Journal of Korean Institute of Communications and Information Sciences}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{48}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{833-841}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.7840/kics.2023.48.7.833}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/central-480.webp 480w,/assets/img/publication_preview/central-800.webp 800w,/assets/img/publication_preview/central-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/central.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="central.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="CentralPoint" class="col-sm-8"> <div class="title">A Central Point-based Analysis for Fingerprint Liveness Detection</div> <div class="author"> Min Young Lim* ,  Tae Yong Kim* ,  Joung Eun Park* ,  <em>Pyo Min Hong*</em> ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>In 2022 13th International Conference on Information and Communication Technology Convergence (ICTC)</em> , 2022 </div> <div class="periodical"> </div> <div class="honor" style="color: #007bff;">Best paper award</div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/abstract/document/9952772" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>To minimize security threats using fake fingerprints, various CNN-based fingerprint liveness detection methods have been proposed. However, since existing methods mainly employ a random crop method, key information of target fingerprint may be overlooked during the training process, which may lead to decreased detection accuracy. In this paper, we propose a new fingerprint liveness detection method based on central point analysis of fingerprints. The proposed method measures a central point of target fingerprint, extracts the crops with different sizes based on the central point, and fuses the liveness scores inferred from each crop-size model. As a result of validating our method using real datasets, it was confirmed that our method effectively detects fake fingerprints compared to existing methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CentralPoint</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lim*, Min Young and Kim*, Tae Yong and Park*, Joung Eun and Hong*, Pyo Min and Lee, Youn Kyu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 13th International Conference on Information and Communication Technology Convergence (ICTC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Central Point-based Analysis for Fingerprint Liveness Detection}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1307-1309}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Training;Fuses;Crops;Fingerprint recognition;Size measurement;Information and communication technology;Security;fingerprint liveness detection;deep learning;central point;score fusion}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICTC55196.2022.9952772}</span><span class="p">,</span>
  <span class="na">honor</span> <span class="p">=</span> <span class="s">{Best paper award}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Pyo Min Hong. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Last updated: December 15, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>