<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Pyo Min Hong </title> <meta name="author" content="Pyo Min Hong"> <meta name="description" content="Publications are listed in reverse chronological order."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/animated.gif?68b851042db05aa2222face22c0729dd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pyomin.github.io/publications/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Pyo Min Hong </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">Publications are listed in reverse chronological order.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/velcro-480.webp 480w,/assets/img/publication_preview/velcro-800.webp 800w,/assets/img/publication_preview/velcro-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/velcro.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="velcro.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="velcro" class="col-sm-8"> <div class="title">VELCRO: A visual-based programming tool for effortless deep learning model construction</div> <div class="author"> Min Young Lim ,  Seong Hee Park ,  Soo-Hyun Lee ,  Jung Won Yoon ,  <em>Pyo Min Hong</em> , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Hwajung Yoo, Kon-Woo Kwon, Jongwook Jeong, Youn Kyu Lee' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>SoftwareX</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://www.sciencedirect.com/science/article/pii/S235271102400027X" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>The development and deployment of deep learning models are currently limited to expert developers due to the requirement for programming expertise, posing challenges for non-expert or inexperienced developers. In this paper, we present VELCRO, a visual-based programming tool that enables intuitive construction, modification, analysis, and generation of deep learning models for both expert and non-expert developers. VELCRO allows users to understand and modify complex architectures of deep learning models using architecture abstraction, and verify architectures through automated architecture validation. Finally, users can convert the user-configured architecture into deep learning code and deploy it in target environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">velcro</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{VELCRO: A visual-based programming tool for effortless deep learning model construction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lim, Min Young and Park, Seong Hee and Lee, Soo-Hyun and Yoon, Jung Won and Hong, Pyo Min and Yoo, Hwajung and Kwon, Kon-Woo and Jeong, Jongwook and Lee, Youn Kyu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{SoftwareX}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{26}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{101656}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/adv2adv-480.webp 480w,/assets/img/publication_preview/adv2adv-800.webp 800w,/assets/img/publication_preview/adv2adv-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/adv2adv.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="adv2adv.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Adv2Adv" class="col-sm-8"> <div class="title">Adversarial2Adversarial: Defending against Adversarial Fingerprint Attacks without Clean Images</div> <div class="author"> <em>Pyo Min Hong</em> ,  So Hyun Kang ,  Jinhyeon Kim ,  Ji Hoo Kim ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>In 2023 14th International Conference on Information and Communication Technology Convergence (ICTC)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/abstract/document/10392544" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>A number of denoising-based methods have been proposed to defend against adversarial fingerprint attacks. However, these methods inherently rely on having a clean image that corresponds to each adversarial fingerprint image. In this paper, we propose a novel denoising-based defense method without the need for clean fingerprint images. Our approach leverages a Noise2Noise mechanism, which performs denoising based on the noisy dataset. This enables us to effectively eliminate any adversarial noise that may be embedded in fingerprint images without training on clean fingerprint images. The experimental results on real-world datasets confirm that our method is robust against untrained adversarial fingerprint attacks while outperforming existing methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Adv2Adv</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adversarial2Adversarial: Defending against Adversarial Fingerprint Attacks without Clean Images}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hong, Pyo Min and Hyun Kang, So and Kim, Jinhyeon and Kim, Ji Hoo and Kyu Lee, Youn}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 14th International Conference on Information and Communication Technology Convergence (ICTC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1278-1282}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Training;Image matching;Face recognition;Noise reduction;Fingerprint recognition;Information and communication technology;Noise measurement;fingerprint liveness detection;adversarial attack;deep learning;denoising}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICTC58733.2023.10392544}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2stage-480.webp 480w,/assets/img/publication_preview/2stage-800.webp 800w,/assets/img/publication_preview/2stage-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/2stage.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2stage.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Purification" class="col-sm-8"> <div class="title">Two-Stage Image Restoration: A Shield against Adversarial Attacks on Face Identification</div> <div class="author"> Min Young Lim ,  <em>Pyo Min Hong</em> ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>In 2023 14th International Conference on Information and Communication Technology Convergence (ICTC)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/abstract/document/10393701" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Various methods have been proposed to defend face identification systems against adversarial attacks by eliminating adversarial perturbations from target face images. However, it is challenging to eliminate such perturbations while preserving the crucial facial features within the images. In this paper, we propose a novel purification method for an effective defense against adversarial attacks on target face images. Our method incorporates a two-stage image restoration utilizing diffusion, consisting of sequential super-resolution-based image restoration followed by colorization-based image restoration. The experimental results demonstrate the effectiveness of our method in eliminating perturbations while preserving the identity of the facial features.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Purification</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lim, Min Young and Hong, Pyo Min and Lee, Youn Kyu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 14th International Conference on Information and Communication Technology Convergence (ICTC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Two-Stage Image Restoration: A Shield against Adversarial Attacks on Face Identification}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1283-1285}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Purification;Perturbation methods;Superresolution;Distortion;Image restoration;Information and communication technology;Faces;defense against adversarial attacks;deep learning;face identification;image restoration}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICTC58733.2023.10393701}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DIP-480.webp 480w,/assets/img/publication_preview/DIP-800.webp 800w,/assets/img/publication_preview/DIP-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/DIP.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DIP.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="diprecon" class="col-sm-8"> <div class="title">Defending Against Adversarial Fingerprint Attacks Based on Deep Image Prior</div> <div class="author"> Hwajung Yoo ,  <em>Pyo Min Hong</em> ,  Taeyong Kim ,  Jung Won Yoon ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>IEEE Access</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/abstract/document/10196440" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Recently, deep learning-based biometric authentication systems, especially fingerprint authentication, have been used widely in real-world. However, these systems are vulnerable to adversarial attacks which prevent deep learning models from distinguishing input data properly. To solve these problems, various defense methods have been proposed, especially utilizing denoising mechanisms, but they provided limited defense performance. In this study, we proposed a new defense method against adversarial fingerprint attacks. To ensure defense performance, we have introduced Deep Image Prior mechanism which has superior performance in image reconstruction without prior training and a large amount of dataset. The proposed method aims to remove adversarial perturbations of the input fingerprint image and reconstruct it close to the original fingerprint image by adapting Deep Image Prior. Our method has achieved robust defense performance against various types of adversarial fingerprint attacks across different datasets, encompassing variations in sensors, shapes, and materials of fingerprint images. Furthermore, our method has demonstrated that it is superior to other image reconstruction methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">diprecon</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yoo, Hwajung and Hong, Pyo Min and Kim, Taeyong and Yoon, Jung Won and Lee, Youn Kyu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Defending Against Adversarial Fingerprint Attacks Based on Deep Image Prior}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{78713-78725}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Fingerprint recognition;Image reconstruction;Image matching;Perturbation methods;Electronics packaging;Noise reduction;Generative adversarial networks;Deep learning;Biometrics (access control);Computer security;Authentication;Adversarial attack defense;image reconstruction;fingerprint authentication system;deep learning;denoising;deep image prior}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2023.3299862}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/central-480.webp 480w,/assets/img/publication_preview/central-800.webp 800w,/assets/img/publication_preview/central-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/central.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="central.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="CentralPoint" class="col-sm-8"> <div class="title">A Central Point-based Analysis for Fingerprint Liveness Detection</div> <div class="author"> Min Young Lim ,  Tae Yong Kim ,  Joung Eun Park ,  <em>Pyo Min Hong</em> ,  and  Youn Kyu Lee </div> <div class="periodical"> <em>In 2022 13th International Conference on Information and Communication Technology Convergence (ICTC)</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/abstract/document/9952772" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>To minimize security threats using fake fingerprints, various CNN-based fingerprint liveness detection methods have been proposed. However, since existing methods mainly employ a random crop method, key information of target fingerprint may be overlooked during the training process, which may lead to decreased detection accuracy. In this paper, we propose a new fingerprint liveness detection method based on central point analysis of fingerprints. The proposed method measures a central point of target fingerprint, extracts the crops with different sizes based on the central point, and fuses the liveness scores inferred from each crop-size model. As a result of validating our method using real datasets, it was confirmed that our method effectively detects fake fingerprints compared to existing methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CentralPoint</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lim, Min Young and Kim, Tae Yong and Park, Joung Eun and Hong, Pyo Min and Lee, Youn Kyu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 13th International Conference on Information and Communication Technology Convergence (ICTC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Central Point-based Analysis for Fingerprint Liveness Detection}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1307-1309}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Training;Fuses;Crops;Fingerprint recognition;Size measurement;Information and communication technology;Security;fingerprint liveness detection;deep learning;central point;score fusion}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICTC55196.2022.9952772}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Pyo Min Hong. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Last updated: March 10, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>