<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Target Aware No-code neural network Generation and Operation framework | Pyo Min Hong </title> <meta name="author" content="Pyo Min Hong"> <meta name="description" content="Supported by Institute for Information communication Technology Planning (IITP), South Korea"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/animated.gif?68b851042db05aa2222face22c0729dd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pyomin.github.io/blog/2024/ETRI/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Pyo Min Hong </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Target Aware No-code neural network Generation and Operation framework</h1> <p class="post-meta"> December 24, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/etri"> <i class="fa-solid fa-hashtag fa-sm"></i> ETRI</a>     ·   <a href="/blog/category/project"> <i class="fa-solid fa-tag fa-sm"></i> Project</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote> <p><strong>Announcement</strong></p> <ul> <li><a href="https://github.com/ML-TANGO/TANGO/releases/tag/tango-24.11" rel="external nofollow noopener" target="_blank">2024 November TANGO Release</a></li> </ul> </blockquote> <hr> <h2 id="introduction-to-tango-">Introduction to TANGO <a name="intro"></a> </h2> <p>TANGO (<strong>T</strong>arget <strong>A</strong>ware <strong>N</strong>o-code neural network <strong>G</strong>eneration and <strong>O</strong>peration framework) is code name of project for Integrated Machine Learning Framework.</p> <p>The TANGO framework is an automated neural network generation and deployment solution designed for novice users with little to no coding expertise. It simplifies the process of creating and deploying neural network applications by providing an intuitive environment, including a project manager and neural network visualization tools. Users are required only to prepare labeled datasets and define target devices. TANGO performs an analysis of the datasets and device characteristics, generates task-specific neural networks aligned with user requirements, trains the models, and packages them as Docker container images for seamless deployment onto the specified target devices.</p> <p>Each component of TANGO is a self-contained service implemented using container technology, interacting with other components through REST APIs. The entire framework can be accessed and executed via <a href="https://github.com/ML-TANGO/TANGO" rel="external nofollow noopener" target="_blank">TANGO GitHub repository</a>.</p> <p>To ensure users understand the neural network architecture, TANGO provides a visual representation of the base model. Our team developed the visualization tools and implemented the code deployment framework to support this functionality. This post provides a brief overview of the implemented features.</p> <p align="center"> <img src="../../../assets/img/Projects/Velcro_0.png" alt="Velcro Viz0" width="800px"> </p> <h3 id="a-layer-tab">A. Layer Tab</h3> <p>The <strong>Layer Tab</strong> represents the types of layers that can be employed when constructing the deep learning architecture.</p> <ul> <li> <strong>Types of layers</strong>: Set based on the official PyTorch documentation and represented as a toggle.</li> <li> <strong>Layers</strong>: Become visible when pressing the type toggle and are color-coded according to their respective types.</li> </ul> <h3 id="b-abstract-tab">B. Abstract Tab</h3> <p>The <strong>Abstract Tab</strong> represents a feature to group the architecture configured by the user and its functionality is divided into auto-group and custom-group.</p> <ul> <li> <strong>Auto-Group</strong>: Automatically groups nodes and edges according to pre-defined levels (e.g., 3 levels in ResNet50) based on key architectural characteristics.</li> <li> <strong>Custom-Group</strong>: Allows users to manually group selected nodes and edges into specific grouping levels based on user-defined criteria.</li> </ul> <h3 id="c-layer-information">C. Layer Information</h3> <p>The <strong>Layer Information</strong> represents a feature to edit the hyperparameters of the layers that consist of the architecture.</p> <h3 id="d-workspace">D. Workspace</h3> <p>The <strong>Workspace</strong> is a space for configuring architecture using the layers from the Layer Tab, and it offers functionalities such as Alignment, Architecture Validation, and Deep Learning Code Generation.</p> <ul> <li> <strong>Alignment</strong>: Vertically aligns the nodes in the workspace to provide a clear and organized view of the architecture.</li> <li> <strong>Architecture Validation</strong>: Displays the results of dimension compatibility validation between nodes in red and parameter variability validation in blue.</li> <li> <strong>Deep Learning Code Generation</strong>: Exports the user-configured architecture as a code file in a format supported by PyTorch (i.e., pth).</li> </ul> <p align="center"> <img src="../../../assets/img/Projects/Velcro_use1.png" alt="Velcro Viz1" width="800px"> </p> <h3 id="a-how-to-construct-architecture">A. How to construct architecture</h3> <ul> <li> <strong>Add Node</strong>: By dragging a layer node from the Layer Selection to Workspace, the desired node is created in the Workspace.</li> <li> <strong>Connect Nodes</strong>: By dragging the top or bottom points of a node to the points of another node, the edge is created between the two nodes.</li> <li> <strong>Eliminate Node or Edge</strong>: By clicking the target node or edge and pressing the backspace key, the target node is eliminated.</li> </ul> <h3 id="b-how-to-set-hyper-parameter">B. How to set hyper-parameter</h3> <ul> <li>By clicking the node in the workspace, you can see the layer information window located at the bottom. Then you can edit the value of hyper-parameters in each field.</li> <li> <strong>Default button</strong>: By clicking the default button located at the bottom-left of the layer information window, the value of hyper-parameters will be changed to the default value.</li> <li> <strong>Save button</strong>: By clicking the save button located at the bottom-right of the layer information window, the value of hyper-parameters will be saved to the database.</li> </ul> <h3 id="c-how-to-scale--align">C. How to scale &amp; align</h3> <ul> <li> <strong>Scaling up &amp; down</strong>: By scrolling the mouse wheel upward, nodes and edges will zoom in for a magnified view. Conversely, by scrolling the mouse wheel downward, nodes and edges will zoom out to show a reduced size.</li> <li> <strong>Architecture Alignment</strong>: By clicking the Alignment button located in the bottom left of the Workspace, the nodes in the Workspace are aligned vertically.</li> </ul> <h3 id="d-how-to-validate-architecture--generate-code">D. How to validate architecture &amp; generate code</h3> <ul> <li> <strong>Architecture Validation</strong>: By clicking the Inspect button located in the bottom right of the Workspace, the results of dimension compatibility between nodes are displayed in red, and parameter variability is displayed in blue.</li> <li> <strong>Deep Learning Code Generation</strong>: By clicking the Generate button located in the bottom right of the Workspace, a code file format (i.e., pth) of the constructed architecture is exported.</li> </ul> <p><img src="../../../assets/img/Projects/Velcro_Group.png" alt="Velcro Viz2" width="800px"></p> <h3 id="e-how-to-auto-group">E. How to auto-group</h3> <ul> <li>By clicking the level buttons, the user can group layers for the desired level.</li> <li>The information about abstracted layers can be found in the group information window.</li> <li> <strong>Levels</strong> <ul> <li>The higher the level, the more layers can be abstracted into groups.</li> <li>For example, in the case of VGG-16, it can be grouped as follows. <ul> <li>Level 1: None of the nodes are represented as a group.</li> <li>Level 2: The “Conv2d”, “BatchNorm2d”, and “ReLU” nodes are represented as a group.</li> <li>Level 3: The “Conv2d”, “BatchNorm2d”, “ReLU”, “Conv2d”, “BatchNorm2d”, “ReLU”, and “MaxPool2d” are represented as one group. And “Conv2d”, “BatchNorm2d”, “ReLU”, “Conv2d”, “BatchNorm2d”, “ReLU”, “Conv2d”, “BatchNorm2d”, “ReLU”, “MaxPool2d” is represented by another group.</li> </ul> </li> </ul> </li> </ul> <h3 id="f-how-to-custom-group">F. How to custom-group</h3> <ul> <li> <strong>How to group</strong> <ul> <li>Select nodes in the workspace and click the ‘Group’ button, the visualized architecture in the workspace automatically groups the chosen nodes and edges into the corresponding grouping level.</li> </ul> </li> <li> <strong>How to ungroup</strong> <ul> <li>Click the ‘Ungroup’ button in the Abstract Architecture Tab, and then the group will be ungrouped.</li> </ul> </li> </ul> <h5 id="key-features-of-the-neural-network-deployment-module">Key features of the Neural Network Deployment Module:</h5> <ul> <li>Ability to convert neural network models into executable code<br> The neural network deployment module provides an automatic generation function for executable code templates, such as pre-processing code for neural network input and post-processing code for interpreting neural network output, so that the neural network model can be operated on the operating system, programming language, and inference engine.</li> </ul> <h2 id="developer-guides-and-references">Developer Guides and References<a name="dev_guides"></a> </h2> <ul> <li><a href="https://github.com/ML-TANGO/TANGO/wiki/Guides-%7C-TANGO-Architecture" rel="external nofollow noopener" target="_blank">TANGO Architecture Overview</a></li> <li><a href="https://github.com/ML-TANGO/TANGO/wiki/Guides-%7C-Container-Port-Map" rel="external nofollow noopener" target="_blank">TANGO Container Port Mapping guide</a></li> <li><a href="https://github.com/ML-TANGO/TANGO/wiki/Guides-%7C-Exchanging-Data-among-Containers" rel="external nofollow noopener" target="_blank">Exchanging Data among Containers</a></li> <li><a href="https://github.com/ML-TANGO/TANGO/wiki/Guides-%7C-Rest-API" rel="external nofollow noopener" target="_blank">TANGO REST API Guide</a></li> <li><a href="https://github.com/user-attachments/files/17841949/how.to.prepare.dataset.for.classification.pdf" rel="external nofollow noopener" target="_blank">how to prepare dataset for classification.pdf</a></li> </ul> <hr> <h2 id="acknowledgement-">Acknowledgement <a name="ack"></a> </h2> <p>This work was supported by <a href="https://www.iitp.kr/" rel="external nofollow noopener" target="_blank">Institute of Information &amp; communications Technology Planning &amp; Evaluation (IITP)</a> grant funded by the Korea government(MSIT) (<strong>No. 2021-0-00766</strong>, <em>Development of Integrated Development Framework that supports Automatic Neural Network Generation and Deployment optimized for Runtime Environment</em>).</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Pyo Min Hong. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Last updated: December 24, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>